#!/usr/bin/env python3
"""
æµ‹è¯•SparseSemiStructuredTensoråŠŸèƒ½å’ŒçœŸæ­£çš„ç¡¬ä»¶åŠ é€Ÿ
"""

import torch
import time
import numpy as np
from typing import Tuple

def check_sparse_support():
    """æ£€æŸ¥å½“å‰ç¯å¢ƒæ˜¯å¦æ”¯æŒSparseSemiStructuredTensor"""
    print("ğŸ” æ£€æŸ¥ç¨€ç–å¼ é‡æ”¯æŒæƒ…å†µ")
    print("="*60)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
        print(f"GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")
        print(f"å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
    
    # æ£€æŸ¥SparseSemiStructuredTensoræ”¯æŒ
    try:
        if hasattr(torch.sparse, 'SparseSemiStructuredTensor'):
            print("âœ… SparseSemiStructuredTensor: æ”¯æŒ")
            return True
        else:
            print("âŒ SparseSemiStructuredTensor: ä¸æ”¯æŒ")
            return False
    except Exception as e:
        print(f"âŒ æ£€æŸ¥ç¨€ç–å¼ é‡æ—¶å‡ºé”™: {e}")
        return False

def create_24_sparse_weight(shape: Tuple[int, int], dtype=torch.float16) -> torch.Tensor:
    """åˆ›å»ºå®Œç¾çš„2:4ç¨€ç–æƒé‡çŸ©é˜µ"""
    weight = torch.zeros(shape, dtype=dtype)
    
    # ç¡®ä¿èƒ½è¢«4æ•´é™¤
    total_elements = weight.numel()
    groups_of_4 = total_elements // 4
    
    # å°†æƒé‡å±•å¹³å¹¶é‡å¡‘ä¸º(groups, 4)
    flat_weight = weight.view(-1)
    weight_groups = flat_weight[:groups_of_4 * 4].view(groups_of_4, 4)
    
    # åœ¨æ¯ç»„4ä¸ªå…ƒç´ ä¸­ï¼Œå‰2ä¸ªè®¾ä¸ºéé›¶
    for i in range(groups_of_4):
        weight_groups[i, :2] = torch.randn(2, dtype=dtype) * 0.1
    
    return weight.contiguous()

def test_sparse_conversion():
    """æµ‹è¯•ç¨€ç–å¼ é‡è½¬æ¢åŠŸèƒ½"""
    print(f"\nğŸ§ª æµ‹è¯•ç¨€ç–å¼ é‡è½¬æ¢")
    print("="*40)
    
    try:
        # åˆ›å»ºæµ‹è¯•æƒé‡ - ç¡®ä¿å½¢çŠ¶é€‚åˆ2:4æ¨¡å¼
        print("ğŸ“¦ åˆ›å»º2:4ç¨€ç–æƒé‡çŸ©é˜µ...")
        weight_shape = (256, 256)  # æ€»å…±65536ä¸ªå…ƒç´ ï¼Œèƒ½è¢«4æ•´é™¤
        dense_weight = create_24_sparse_weight(weight_shape, torch.float16)
        
        print(f"æƒé‡å½¢çŠ¶: {dense_weight.shape}")
        print(f"æƒé‡ç¨€ç–åº¦: {(dense_weight == 0).float().mean().item():.1%}")
        
        # éªŒè¯2:4æ¨¡å¼
        flat_weight = dense_weight.view(-1)
        groups_of_4 = flat_weight.view(-1, 4)
        zero_counts = (groups_of_4 == 0).sum(dim=1)
        perfect_24_groups = (zero_counts == 2).sum().item()
        total_groups = groups_of_4.shape[0]
        compliance_rate = perfect_24_groups / total_groups
        
        print(f"2:4åˆè§„ç‡: {compliance_rate:.1%}")
        
        if compliance_rate < 0.99:
            print("âš ï¸ æƒé‡ä¸æ˜¯å®Œç¾çš„2:4æ¨¡å¼ï¼Œåˆ›å»ºå®Œç¾çš„2:4æƒé‡...")
            # é‡æ–°åˆ›å»ºç¡®ä¿å®Œç¾2:4
            flat_weight = dense_weight.view(-1)
            groups_of_4 = flat_weight.view(-1, 4)
            # å¼ºåˆ¶æ¯ç»„å‰2ä¸ªéé›¶ï¼Œå2ä¸ªä¸ºé›¶
            groups_of_4[:, :2] = torch.randn(groups_of_4.shape[0], 2, dtype=torch.float16) * 0.1
            groups_of_4[:, 2:] = 0
            dense_weight = flat_weight.view(weight_shape)
            
            # é‡æ–°éªŒè¯
            zero_counts = (groups_of_4 == 0).sum(dim=1)
            perfect_24_groups = (zero_counts == 2).sum().item()
            compliance_rate = perfect_24_groups / total_groups
            print(f"ä¿®æ­£å2:4åˆè§„ç‡: {compliance_rate:.1%}")
        
        # ç§»åˆ°GPU
        if torch.cuda.is_available():
            dense_weight = dense_weight.cuda()
            print(f"âœ… æƒé‡å·²ç§»è‡³GPU")
        
        # å°è¯•è½¬æ¢ä¸ºç¨€ç–å¼ é‡
        print("ğŸ”§ å°è¯•è½¬æ¢ä¸ºSparseSemiStructuredTensor...")
        
        # è®¾ç½®å¼ºåˆ¶ä½¿ç”¨CUTLASS
        if hasattr(torch.sparse, 'SparseSemiStructuredTensor'):
            torch.sparse.SparseSemiStructuredTensor._FORCE_CUTLASS = True
            print("âœ… å·²å¯ç”¨CUTLASSåŠ é€Ÿ")
        
        sparse_weight = torch.sparse.to_sparse_semi_structured(dense_weight)
        print("âœ… æˆåŠŸè½¬æ¢ä¸ºSparseSemiStructuredTensor!")
        print(f"ç¨€ç–å¼ é‡ç±»å‹: {type(sparse_weight)}")
        print(f"ç¨€ç–å¼ é‡å½¢çŠ¶: {sparse_weight.shape}")
        print(f"ç¨€ç–å¼ é‡è®¾å¤‡: {sparse_weight.device}")
        
        return dense_weight, sparse_weight
        
    except Exception as e:
        print(f"âŒ ç¨€ç–å¼ é‡è½¬æ¢å¤±è´¥: {e}")
        print("ğŸ’¡ å¯èƒ½éœ€è¦æ›´æ–°PyTorchç‰ˆæœ¬æˆ–GPUä¸æ”¯æŒ")
        return None, None

def benchmark_matmul_performance(dense_weight: torch.Tensor, sparse_weight: torch.Tensor):
    """å¯¹æ¯”å¯†é›†çŸ©é˜µå’Œç¨€ç–çŸ©é˜µçš„è¿ç®—æ€§èƒ½"""
    print(f"\nâš¡ æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("="*40)
    
    if dense_weight is None or sparse_weight is None:
        print("âŒ æ— æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œç¨€ç–å¼ é‡è½¬æ¢å¤±è´¥")
        return
    
    # åˆ›å»ºè¾“å…¥å¼ é‡
    batch_size = 32
    input_size = dense_weight.shape[1]
    x = torch.randn(batch_size, input_size, dtype=torch.float16, device=dense_weight.device)
    
    # é¢„çƒ­
    print("ğŸ”¥ GPUé¢„çƒ­...")
    for _ in range(10):
        _ = torch.matmul(x, dense_weight.T)
        _ = torch.matmul(x, sparse_weight.T)
    
    torch.cuda.synchronize()
    
    # æµ‹è¯•å¯†é›†çŸ©é˜µè¿ç®—
    print("ğŸ“Š æµ‹è¯•å¯†é›†çŸ©é˜µè¿ç®—...")
    torch.cuda.synchronize()
    start_time = time.time()
    
    for _ in range(100):
        result_dense = torch.matmul(x, dense_weight.T)
    
    torch.cuda.synchronize()
    dense_time = time.time() - start_time
    
    # æµ‹è¯•ç¨€ç–çŸ©é˜µè¿ç®—
    print("ğŸ“Š æµ‹è¯•ç¨€ç–çŸ©é˜µè¿ç®—...")
    torch.cuda.synchronize()
    start_time = time.time()
    
    for _ in range(100):
        result_sparse = torch.matmul(x, sparse_weight.T)
    
    torch.cuda.synchronize()
    sparse_time = time.time() - start_time
    
    # è®¡ç®—åŠ é€Ÿæ¯”
    speedup = dense_time / sparse_time
    
    print(f"\nğŸ“ˆ æ€§èƒ½ç»“æœ:")
    print(f"  å¯†é›†çŸ©é˜µæ—¶é—´: {dense_time:.4f}s")
    print(f"  ç¨€ç–çŸ©é˜µæ—¶é—´: {sparse_time:.4f}s")
    print(f"  åŠ é€Ÿæ¯”: {speedup:.2f}x")
    
    # éªŒè¯ç»“æœä¸€è‡´æ€§
    error = torch.max(torch.abs(result_dense - result_sparse)).item()
    print(f"  ç»“æœè¯¯å·®: {error:.6f}")
    
    if speedup > 1.1:
        print("ğŸ‰ è·å¾—äº†æ˜¾è‘—çš„ç¡¬ä»¶åŠ é€Ÿ!")
    elif speedup > 1.0:
        print("âœ… è·å¾—äº†è½»å¾®çš„åŠ é€Ÿ")
    else:
        print("âš ï¸ æ²¡æœ‰è·å¾—åŠ é€Ÿï¼Œå¯èƒ½éœ€è¦è°ƒæ•´")
    
    return speedup

def test_model_weight_conversion():
    """æµ‹è¯•å°†æ¨¡å‹æƒé‡è½¬æ¢ä¸ºç¨€ç–æ ¼å¼"""
    print(f"\nğŸ”„ æµ‹è¯•æ¨¡å‹æƒé‡è½¬æ¢")
    print("="*40)
    
    try:
        # åŠ è½½ä½ çš„å‰ªææ¨¡å‹
        model_path = "/data/xay/MaskDM/finetuned_results/masked_full_finetuned_v2/pruned/unet_ema_pruned.pth"
        print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path}")
        
        model_state = torch.load(model_path, map_location='cpu')
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        converted_weights = {}
        conversion_count = 0
        
        for name, param in model_state.items():
            if 'weight' in name and param.dim() >= 2 and param.numel() > 1000:
                # æ£€æŸ¥æ˜¯å¦ç¬¦åˆ2:4æ¨¡å¼
                flat_param = param.view(-1)
                if flat_param.numel() % 4 == 0:
                    groups_of_4 = flat_param.view(-1, 4)
                    zero_counts = (groups_of_4 == 0).sum(dim=1)
                    perfect_24_groups = (zero_counts == 2).sum().item()
                    total_groups = groups_of_4.shape[0]
                    compliance_rate = perfect_24_groups / total_groups
                    
                    if compliance_rate > 0.8:  # è‡³å°‘80%ç¬¦åˆ2:4æ¨¡å¼
                        try:
                            # è½¬æ¢ä¸ºFP16å¹¶ç§»åˆ°GPU
                            weight_fp16 = param.to(torch.float16).cuda()
                            
                            # å°è¯•è½¬æ¢ä¸ºç¨€ç–å¼ é‡
                            sparse_weight = torch.sparse.to_sparse_semi_structured(weight_fp16)
                            converted_weights[name] = {
                                'original': param,
                                'sparse': sparse_weight,
                                'compliance': compliance_rate
                            }
                            conversion_count += 1
                            print(f"âœ… {name}: è½¬æ¢æˆåŠŸ (åˆè§„ç‡: {compliance_rate:.1%})")
                            
                        except Exception as e:
                            print(f"âš ï¸ {name}: è½¬æ¢å¤±è´¥ - {e}")
        
        print(f"\nğŸ“Š è½¬æ¢ç»Ÿè®¡:")
        print(f"  æˆåŠŸè½¬æ¢å±‚æ•°: {conversion_count}")
        print(f"  æ€»æƒé‡å±‚æ•°: {len([n for n in model_state.keys() if 'weight' in n])}")
        
        if conversion_count > 0:
            print("ğŸ‰ éƒ¨åˆ†æ¨¡å‹æƒé‡æˆåŠŸè½¬æ¢ä¸ºç¡¬ä»¶åŠ é€Ÿæ ¼å¼!")
            return converted_weights
        else:
            print("âŒ æ²¡æœ‰æƒé‡èƒ½å¤Ÿè½¬æ¢ä¸ºç¨€ç–æ ¼å¼")
            return None
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æƒé‡è½¬æ¢å¤±è´¥: {e}")
        return None

def main():
    print("ğŸš€ SparseSemiStructuredTensoråŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    # æ£€æŸ¥æ”¯æŒæƒ…å†µ
    if not check_sparse_support():
        print("\nâŒ å½“å‰ç¯å¢ƒä¸æ”¯æŒSparseSemiStructuredTensor")
        print("ğŸ’¡ éœ€è¦PyTorch >= 2.1.0 ä¸”GPUæ”¯æŒç¨€ç–è¿ç®—")
        return
    
    # æµ‹è¯•ç¨€ç–å¼ é‡è½¬æ¢
    dense_weight, sparse_weight = test_sparse_conversion()
    
    # æ€§èƒ½åŸºå‡†æµ‹è¯•
    if dense_weight is not None and sparse_weight is not None:
        speedup = benchmark_matmul_performance(dense_weight, sparse_weight)
    
    # æµ‹è¯•æ¨¡å‹æƒé‡è½¬æ¢
    converted_weights = test_model_weight_conversion()
    
    print(f"\nğŸ¯ æ€»ç»“:")
    print("="*40)
    if dense_weight is not None:
        print("âœ… SparseSemiStructuredTensoråŠŸèƒ½æ­£å¸¸")
        if 'speedup' in locals() and speedup > 1.0:
            print(f"âš¡ è·å¾—äº† {speedup:.2f}x ç¡¬ä»¶åŠ é€Ÿ")
        else:
            print("âš ï¸ æœªè·å¾—æ˜æ˜¾åŠ é€Ÿ")
    else:
        print("âŒ SparseSemiStructuredTensoråŠŸèƒ½å¼‚å¸¸")
    
    if converted_weights and len(converted_weights) > 0:
        print(f"ğŸ”„ {len(converted_weights)}ä¸ªæ¨¡å‹æƒé‡å·²è½¬æ¢ä¸ºç¨€ç–æ ¼å¼")
    else:
        print("âŒ æ¨¡å‹æƒé‡æ— æ³•è½¬æ¢ä¸ºç¨€ç–æ ¼å¼")

if __name__ == "__main__":
    main()
